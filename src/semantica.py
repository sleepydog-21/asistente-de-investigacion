import os
import json
import subprocess
from openai import OpenAI
from dotenv import load_dotenv
from datetime import datetime

# ConfiguraciÃ³n
load_dotenv(dotenv_path="credentials/.env")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

fulltext_dir = "data/papers_fulltext"
abstracts_path = "data/fragments/fragments.json"
resumen_path = "data/descarga_resumen.json"
resumenes_dir = "resumenes"
os.makedirs(resumenes_dir, exist_ok=True)

# Historial
historial = []

def guardar_resumen(historial):
    resumen_texto = ""
    for paso in historial:
        resumen_texto += f"ğŸ§ Pregunta: {paso['pregunta']}\n\n"
        resumen_texto += f"ğŸ’¬ Respuesta:\n{paso['respuesta']}\n\n"
        resumen_texto += "ğŸ“š Fuentes:\n"
        for cita in paso['fuentes']:
            resumen_texto += f"- {cita}\n"
        resumen_texto += "\n" + ("=" * 50) + "\n\n"

    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
    resumen_path_out = os.path.join(resumenes_dir, f"resumen_{timestamp}.md")
    with open(resumen_path_out, "w", encoding="utf-8") as f:
        f.write(resumen_texto)
    print(f"ğŸ“ Resumen guardado en {resumen_path_out}")

# Cargar abstracts
abstracts = []
fuentes = []
if os.path.exists(abstracts_path):
    with open(abstracts_path, encoding="utf-8") as f:
        fragments = json.load(f)
        for frag in fragments:
            abstracts.append(frag)

# Chat principal
print("\nğŸ” BÃºsqueda semÃ¡ntica (modo palabras clave en abstract)")
print("Escribe tu tÃ©rmino de bÃºsqueda. Usa 'resumen' para guardar o 'salir' para terminar.\n")

while True:
    pregunta = input(">> Tu bÃºsqueda: ").strip()
    if pregunta.lower() in ("salir", "exit", "quit"):
        print("ğŸ‘‹ SesiÃ³n finalizada.")
        break

    if pregunta.lower() == "resumen":
        if historial:
            guardar_resumen(historial)
        else:
            print("âš ï¸ No hay historial para resumir.")
        continue

    print("\nğŸ” Buscando artÃ­culos que contienen palabras clave en su abstract...\n")
    keywords = pregunta.lower().split()
    encontrados = [
        frag for frag in abstracts
        if any(kw in frag["text"].lower() for kw in keywords)
    ]

    if not encontrados:
        print("âš ï¸ No se encontraron coincidencias en los abstracts.")
        actualizar = input("Â¿Deseas actualizar la base con este tema? (S/N): ").strip().lower()
        if actualizar == "s":
            subprocess.run(["python", "src/descargar_articulos_pubmed.py", pregunta], check=True)
            subprocess.run(["python", "src/fragmentar_abstracts.py"], check=True)
            subprocess.run(["python", "src/generar_embeddings.py"], check=True)
            with open(resumen_path, "w", encoding="utf-8") as f:
                f.write("[]")
            print("âœ… Base actualizada. Intenta hacer tu bÃºsqueda nuevamente.")
        continue

    top5 = encontrados[:5]
    resumenes = "\n\n".join([frag["text"] for frag in top5])
    fuentes = [frag["title"] for frag in top5]

    print("\nğŸ¤– Generando resumen con GPT-4-turbo...\n")
    try:
        completion = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Eres un asistente cientÃ­fico. Resume lo mÃ¡s relevante de los abstracts proporcionados."},
                {"role": "user", "content": f"Resumen de artÃ­culos con las palabras clave '{pregunta}':\n{resumenes}"}
            ],
            temperature=0.3
        )
        respuesta = completion.choices[0].message.content.strip()
        print(respuesta)

        historial.append({
            "pregunta": pregunta,
            "respuesta": respuesta,
            "fuentes": fuentes
        })

    except Exception as e:
        print("âŒ Error al generar respuesta:", e)
