# Asistente de Investigaci√≥n con Memoria

Este proyecto es un asistente de investigaci√≥n ejecutado desde consola, especializado inicialmente en biolog√≠a molecular. Implementa un sistema de RAG (Retrieval-Augmented Generation) para responder preguntas usando informaci√≥n contenida en art√≠culos cient√≠ficos, manteniendo el contexto de la conversaci√≥n, actualizando su base de conocimiento y citando autom√°ticamente las fuentes consultadas.

## Objetivos del proyecto

1. **RAG con actualizaci√≥n de conocimiento**: Buscar respuestas en una base local de art√≠culos y actualizarla si es necesario.
2. **Evitar la p√©rdida de contexto**: Mantener un historial resumible de la conversaci√≥n por sesi√≥n.
3. **Citaci√≥n autom√°tica**: Incluir al final de cada respuesta las fuentes utilizadas.
4. **B√∫squeda sem√°ntica**: Buscar art√≠culos relevantes a partir de una consulta mediante embeddings.

---

## Estructura de carpetas

```
asistente_bio/
‚îú‚îÄ‚îÄ credentials/            # Llave de OpenAI (.env)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ papers_raw/         # Archivos JSON con metadatos de los art√≠culos
‚îÇ   ‚îú‚îÄ‚îÄ papers_fulltext/    # Texto completo descargado
‚îÇ   ‚îú‚îÄ‚îÄ fragments/          # Abstracts divididos
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/         # Archivo FAISS + metadatos
‚îÇ   ‚îî‚îÄ‚îÄ descarga_resumen.json  # Lista temporal de art√≠culos nuevos
‚îú‚îÄ‚îÄ resumenes/              # Res√∫menes por sesi√≥n y resultados generados
‚îú‚îÄ‚îÄ logs/                   # Conversaciones con fuentes y respuestas
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ asistente_principal.py       # Men√∫ principal de interacci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ chat_asistente.py            # Chat con memoria por sesi√≥n y actualizaci√≥n autom√°tica
‚îÇ   ‚îú‚îÄ‚îÄ comparar_articulos.py        # Comparaci√≥n entre dos art√≠culos cient√≠ficos
‚îÇ   ‚îú‚îÄ‚îÄ resumen_articulo.py          # Resumen individual de un art√≠culo completo
‚îÇ   ‚îú‚îÄ‚îÄ busqueda_semantica.py        # B√∫squeda por palabra clave en abstracts
‚îÇ   ‚îú‚îÄ‚îÄ descargar_articulos_pubmed.py# Descarga art√≠culos desde EuropePMC
‚îÇ   ‚îú‚îÄ‚îÄ fragmentar_abstracts.py      # Extrae los abstracts de los art√≠culos descargados
‚îÇ   ‚îî‚îÄ‚îÄ generar_embeddings.py        # Genera embeddings de los abstracts
```

---

## Flujo general del programa

```mermaid
graph TD
A[Usuario hace pregunta] --> B[Buscar en embeddings existentes]
B -->|Suficientemente relevante| C[Extraer texto completo de art√≠culos]
C --> D[Generar respuesta con GPT-4-turbo]
B -->|Nada relevante| E[Ofrecer actualizar base]
E -->|Aceptar| F[Descargar nuevos art√≠culos]
F --> G[Fragmentar abstracts]
G --> H[Generar embeddings]
H --> B
D --> I[Mostrar respuesta y fuentes]
I --> J[Guardar en historial]
```

---

## Descripci√≥n de los programas

### `asistente_principal.py`

Men√∫ central desde el cual el usuario puede escoger una de las siguientes opciones:

1. üìÑ **Resumen de un art√≠culo**: permite al usuario buscar por palabra clave, elegir entre m√∫ltiples coincidencias y recibir un resumen generado autom√°ticamente con GPT-4-turbo. El usuario puede optar por guardar el resumen en `resumenes/`.

2. üìä **Comparaci√≥n entre art√≠culos**: lista todos los art√≠culos disponibles, permite seleccionar dos y genera una comparaci√≥n cr√≠tica utilizando GPT-4-turbo. Las diferencias y similitudes se presentan de forma clara y estructurada, y se pueden guardar como archivo markdown.

3. üîç **B√∫squeda sem√°ntica**: busca por palabras clave en abstracts. Si no hay coincidencias, permite descargar nuevos art√≠culos y actualizar la base. Genera una respuesta basada solo en los textos encontrados, citando fuentes.

4. üí¨ **Asistente en chat**: modo interactivo tipo chat que mantiene el contexto durante la sesi√≥n. Usa embeddings y texto completo, y propone actualizar la base si no encuentra informaci√≥n suficiente.

---

## Scripts auxiliares

### `descargar_articulos_pubmed.py`

Realiza b√∫squedas en EuropePMC. Descarga metadatos (ID, t√≠tulo, autores, a√±o, abstract) y texto completo (cuando est√° disponible). Almacena la informaci√≥n en `papers_raw/` y `papers_fulltext/` y registra las descargas en `descarga_resumen.json`.

### `fragmentar_abstracts.py`

Extrae los campos de abstract de los art√≠culos en `papers_raw/` y los guarda como fragmentos estructurados en `fragments/fragments.json`. Cada fragmento tiene un identificador √∫nico, t√≠tulo, a√±o, autores y el abstract.

### `generar_embeddings.py`

Genera vectores de embeddings utilizando el modelo `text-embedding-3-small` de OpenAI. Los vectores se almacenan como √≠ndice FAISS (`index.faiss`) junto con metadatos para b√∫squedas r√°pidas por similitud sem√°ntica.

---

## Modelos utilizados

* üî§ **`text-embedding-3-small`** (OpenAI): usado para convertir cada abstract en un vector sem√°ntico de dimensi√≥n 1536, que se almacena en un √≠ndice FAISS para b√∫squeda r√°pida.
 **`gpt-4-turbo`** (OpenAI): utilizado para generar respuestas naturales a preguntas, producir res√∫menes individuales, comparar art√≠culos y responder en modo chat. Todas las interacciones generativas del asistente se basan en este modelo.

---

## Requisitos

* Python 3.10 o superior
* Paquetes necesarios:

```bash
pip install openai faiss-cpu tqdm requests python-dotenv
```

Tambi√©n necesitas un archivo `.env` en la carpeta `credentials/` con tu clave:

```
OPENAI_API_KEY=sk-...
```

---

## Ejecuci√≥n del asistente

```bash
python src/asistente_principal.py
```

---

## Estado actual

* [x] Descarga de art√≠culos cient√≠ficos
* [x] Fragmentaci√≥n de abstracts
* [x] Generaci√≥n de embeddings sem√°nticos
* [x] RAG con b√∫squeda contextual y citaci√≥n autom√°tica
* [x] Chat interactivo con historial de sesi√≥n
* [x] Resumen de art√≠culos individuales
* [x] Comparaci√≥n cr√≠tica entre dos art√≠culos
* [x] Men√∫ principal funcional

---

## Licencia

MIT
